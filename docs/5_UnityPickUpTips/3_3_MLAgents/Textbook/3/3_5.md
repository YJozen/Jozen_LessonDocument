# 3-5 学習設定ファイル

2の「学習と推論」での設定について

ここで紹介するもの以外に「セルフプレイ」「Curiosity」「模倣学習」「LSTM」専用のパラメータも存在しますがそちらは４で言及します

<br>

## 学習設定ファイルとは

「学習設定ファイル」(*.yaml)は、学習に利用するハイパーパラメータを設定するファイルです。  
機械学習のパラメータの中で、人間が調整sする必要があるパラメータのことを「ハイパーパラメータ」と呼びます。  
学習設定ファイルは１環境につき１つ用意する必要があります。

### PPOとSAC

「Unity ML-Agents」で標準で使える強化学習アルゴリズムは「PPO」と「SAC」になります。

慣れないうちはPPOを使うことで問題ありません。

PPOとSAOの違いは[別の章](../4/4_1.md)で解説します



```
・PPO（Proximal Policy Optimization）
・SAC（Soft Actor-Critic）
```


<br>

## PPOの学習設定ファイルの例

「PPO」の学習設定ファイルの例は、次の通りです。  
最上位セクション「behaviors:」の下にセクション「<Behavior Name>:」を配置し、さらにその下に各種ハイパーパラメーターを設定します。「Behavior Name」は、「Behavior Parameters」で設定するポリシー毎の識別子になります。

```yaml
behaviors:
  RollerBall:
    #トレーナー識別
    trainer_type: ppo 
    
    #基本
    max_steps: 500000
    time_horizon: 64
    summary_freq: 1000
    keep_checkpoints: 5

    #学習アルゴリズム
    hyperparameters:
      #PPOとSAC共通
      batch_size: 10
      buffer_size: 100
      learning_rate: 0.0003
      learning_rate_schedule: linear

      #PPO用
      beta: 0.005
      epsilon: 0.2
      lambd: 0.95
      num_epoch: 3
    
    #ニューラルネットワーク
    network_settings:
      normalize: true
      hidden_units: 128
      num_layers: 2

    #報酬
    reward_signals:
      extrinsic:
        gamma: 0.99
        strength: 1.0

```


<br>

```yaml
behaviors:
  #トレーナー識別  
  RollerBall:
    trainer_type: sac

    max_steps: 500000
    time_horizon: 64
    summary_freq: 1000
    keep_checkpoints: 5

    hyperparameters:
      batch_size: 64
      buffer_size: 12000
      learning_rate: 0.0003
      learning_rate_schedule: constant

      #SAC専用
      buffer_init_steps: 0
      tau: 0.005
      steps_per_update: 10.0
      save_replay_buffer: false
      init_entcoef: 0.01
      reward_signal_steps_per_update: 10.0

    network_settings:
      normalize: true
      hidden_units: 128
      num_layers: 2

    reward_signals:
      extrinsic:
        gamma: 0.99
        strength: 1.0


```


<br>

## `behaviors` セクション
- `RollerBall`: これはエージェントのビヘイビア名です。ML-Agentsでエージェントに割り当てる名前で、スクリプトと一致する必要があります。

<br>

## トレーナーの種別
#### `trainer_type`
- `ppo`: 使用するトレーナーの種類を指定します。ここではPPOを使用しています。

## 基本のハイパーパラメーター

基本のパラメーターは次の通りです。
#### `max_steps`
- エージェントが学習を終了するまでの最大ステップ数。(デフォルト:500000)  
複雑な問題の場合、この値を増やす必要があります。  
例えば `5e6` は500万ステップを意味します。  

#### `time_horizon`
- 経験バッファに追加する前に、エージェント毎に収集する経験の数(デフォルト：64)。
PPOでは、エピソード内で頻繁に報酬が与えられる場合は小さな値。そうでない場合は大きい値が良いです。エージェントの行動シーケンス内の重要な動作をキャプチャのに十分な大きさでなければなりません。  
SACでは、このパラメータはさほど重要ではなく、通常おおよそのエピソード長を設定すれば問題ありません。
  
(エージェントが経験を蓄積するためにどのくらいの時間を考慮するか。これを小さくすると短期的な動作に対する反応が強化され、大きくすると長期的な報酬に対する考慮が強化されます。)

#### `summary_freq`
- 統計情報を何ステップ毎に保存するか。学習の進行状況が出力される頻度（デフォルト：5000ステップ）。このステップ数ごとに進行状況が記録されます。TensorBordで表示するグラフの粒度も変わります。

#### ``
- 

#### ``
- 

#### `threaded`
- 並列実行を有効にするかどうか。複数のスレッドでトレーニングを行う場合に`true`にします。

#### ``
- 


## 学習アルゴリズム

### PPOとSAC共通

#### `hyperparameters`（ハイパーパラメータ）

- **`batch_size`**: バッチごとの学習サンプルの数。大きいほど安定するが、学習に時間がかかる可能性があります。

- **`buffer_size`**: 一度にバッファに蓄積される経験の総数。バッチを作成するために使用されます。
- **`learning_rate`**: 学習率。大きいほど速く学習するが、不安定になる可能性があり、小さすぎると収束が遅くなります。

- **`learning_rate_schedule`**: 学習率が時間とともにどのように変わるかを設定。ここでは線形的に減少する設定です。

### PPO用

- **`beta`**: エントロピー正則化係数。エージェントの行動のランダム性を維持するためのもの。小さくすると決定的な行動を取るようになります。

・

- **`epsilon`**: PPO特有のクリップ範囲。大きいほど、更新が行動ポリシーから外れることを許可しますが、不安定になる可能性があります。

・

- **`lambd`**: GAE（Generalized Advantage Estimation）に使われるパラメータ。将来の報酬予測に関与します。

・

- **`num_epoch`**: 学習する際のバッファからバッチをどれだけ繰り返して使用するかの回数。

・



### SAC用

#### ``
- 

#### ``
- 

#### ``
- 

#### ``
- 

#### ``
- 

#### ``
- 










## ニューラルネットワーク



#### `network_settings`（ネットワーク設定）
- **`normalize`**: 観察データを正規化するかどうか。学習を安定させるために`true`にするのが一般的です。
- **`hidden_units`**: 各レイヤーの隠れユニット数。値が大きいほど複雑なパターンを学習できるが、学習時間が増えます。
- **`num_layers`**: ニューラルネットワークのレイヤー数。
- **`vis_encode_type`**: ビジュアル観察のエンコーダーの種類（もし視覚入力がある場合）。


#### ``
- 


## 環境報酬

#### `reward_signals`（報酬信号）
- **`extrinsic`**: 外的報酬。環境から与えられる報酬を設定します。

  - **`strength`**: この報酬信号の強さを設定。

  - **`gamma`**: 割引率。将来の報酬の重要度をどれだけ考慮するか。




# 勾配降下

①

②

③

④



# num_layers と　hidden_units
「」



# time_horizon　と　buffer_size

<img src="images/.JPG" width="90%" alt="" title="">



# ・ハイパーパラメーターの用途別まとめ





<br>


<br>
















これらの設定を調整することで、エージェントの学習速度やパフォーマンスをコントロールできます。





















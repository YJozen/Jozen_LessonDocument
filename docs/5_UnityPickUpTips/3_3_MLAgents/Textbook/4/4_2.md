# Discrete

2のRollerBallでは、行動を「Continuous」として学習しましたが、これを「Discrete」にカスタマイズして学習させてみる


## Discreteの学習環境の準備
「Discrete」は、離散値の要素を持つ整数配列
```
「行動」
・Discrete（サイズ１）
　0:移動(0:1:2:3:4:)
```

学習環境のカスタマイズの手順

### ①「BehaviorParameters」を以下のように設定



### ②スクリプト「RollerAgent.cs」のOnActionReceived()を以下のように変更
「RollerAgent.cs」の一部
```cs

```


### ③スクリプト「RollerAgent.cs」のHeuristic()を以下のように変更
「RollerAgent.cs」の一部
```cs

```
<br>

## Discreteの学習設定ファイルの設定

```yaml
behaviors:
  DiscreteEx:
    trainer_type: ppo

    max_steps: 500000
    time_horizon: 64
    summary_freq: 1000
    keep_checkpoints: 5

    hyperparameters:
      batch_size: 128
      buffer_size: 2048
      learning_rate: 0.0003
      learning_rate_schedule: linear

      beta: 0.005
      epsilon: 0.2
      lambd: 0.95
      num_epoch: 3

    network_settings:
      normalize: false
      hidden_units: 128
      num_layers: 2

    reward_signals:
      extrinsic:
        gamma: 0.99
        strength: 1.0

```


## Discreteの学習の実行







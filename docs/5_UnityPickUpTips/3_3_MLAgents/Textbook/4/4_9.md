# 4-9 カリキュラム学習

「カリキュラム学習」はタスクの難易度を徐々に上げていくことで、より難しいタスクの攻略を可能にする学習方法です。

<br>

## カリキュラム学習とは


<img src="images/4_9.JPG" width="90%" alt="" title="">

## カリキュラム学習の実装手順



<br>

## カリキュラム学習の学習環境の準備

<img src="images/4_9_2.png" width="90%" alt="" title="">


<br>

## 環境パラメータの準備



<br>

## 環境パラメータの実装

「RaycastAgent.cs」全体
```cs
using System.Collections.Generic;
using UnityEngine;
using Unity.MLAgents;
using Unity.MLAgents.Sensors;
using Unity.MLAgents.Actuators;
using Unity.MLAgents.Policies;

// RaycastAgent
public class RaycastAgent : Agent
{
    Rigidbody rBody;
    int lastCheckPoint; // 最終チェックポイント
    int checkPointCount; // チェックポイント通過数

    // ゲームオブジェクト生成時に呼ばれる
    public override void Initialize()
    {
        this.rBody = GetComponent<Rigidbody>();
    }

    // 環境パラメータ
    float checkPointReward;
    float episodeReward;
    float stepReward;

    // エピソード開始時に呼ばれる
    public override void OnEpisodeBegin()
    {
        // 周回数の環境
        this.lastCheckPoint = 0;
        this.checkPointCount = 0;

        // 環境パラメータの設定
        EnvironmentParameters envParams = Academy.Instance.EnvironmentParameters;
        this.checkPointReward = envParams.GetWithDefault("checkpoint_reward", 0.0f);
        this.episodeReward = envParams.GetWithDefault("episode_reward", 2.0f);
        this.stepReward = envParams.GetWithDefault("step_reward", -0.001f);
    }

    // 状態取得時に呼ばれる
    public override void CollectObservations(VectorSensor sensor)
    {
        sensor.AddObservation(rBody.velocity.x); // RaycastAgentのX速度
        sensor.AddObservation(rBody.velocity.z); // RaycastAgentのZ速度
    }

    // 行動実行時に呼ばれる
    public override void OnActionReceived(ActionBuffers actionBuffers)
    {
        // RaycastAgentに力を加える
        Vector3 dirToGo = Vector3.zero;
        Vector3 rotateDir = Vector3.zero;
        int action = actionBuffers.DiscreteActions[0];
        if (action == 1) dirToGo = transform.forward;
        if (action == 2) dirToGo = transform.forward * -1.0f;
        if (action == 3) rotateDir = transform.up * -1.0f;
        if (action == 4) rotateDir = transform.up;
        this.transform.Rotate(rotateDir, Time.deltaTime * 200f);
        this.rBody.AddForce(dirToGo * 0.4f, ForceMode.VelocityChange);

        // ステップ毎の報酬
        AddReward(this.stepReward);
    }

    // チェックポイントに衝突時に呼ばれる
    public void EnterCheckPoint(int checkPoint)
    {
        // 次のチェックポイントに衝突
        if (checkPoint == (this.lastCheckPoint+1)%4)
        {
            // チェックポイント毎のプラス報酬
            AddReward(this.checkPointReward);
            this.checkPointCount++;

            // ゴール
            if (this.checkPointCount >= 4)
            {
                // エピソード毎の報酬
                AddReward(this.episodeReward);
                EndEpisode();
            }
        }
        // 前のチェックポイントに衝突
        else if (checkPoint == (this.lastCheckPoint-1+4)%4)
        {
            // チェックポイント毎の・マイナス報酬
            AddReward(-this.checkPointReward);
            this.checkPointCount--;
        }

        // 最終チェックポイントの更新
        this.lastCheckPoint = checkPoint;
    }

    // ヒューリスティックモードの行動決定時に呼ばれる
    public override void Heuristic(in ActionBuffers actionBuffers)
    {
        var actionsOut = actionBuffers.DiscreteActions;
        actionsOut[0] = 0;
        if (Input.GetKey(KeyCode.UpArrow)) actionsOut[0] = 1;
        if (Input.GetKey(KeyCode.DownArrow)) actionsOut[0] = 2;
        if (Input.GetKey(KeyCode.LeftArrow)) actionsOut[0] = 3;
        if (Input.GetKey(KeyCode.RightArrow)) actionsOut[0] = 4;
    }
}

```


<br>


## カリキュラム学習の学習設定ファイルの設定

今回は「PPO」で学習します。以下のようにパラメータを設定してください。

```yaml 
behaviors:
  CurriculumEx:
    trainer_type: ppo

    max_steps: 10000000
    time_horizon: 128
    summary_freq: 10000
    keep_checkpoints: 5

    hyperparameters:
      batch_size: 128
      buffer_size: 2048
      learning_rate: 0.0003
      learning_rate_schedule: linear

      beta: 0.01
      epsilon: 0.2
      lambd: 0.95
      num_epoch: 3

    network_settings:
      normalize: false
      hidden_units: 512
      num_layers: 2

    reward_signals:
      extrinsic:
        gamma: 0.99
        strength: 1.0

environment_parameters:
  checkpoint_reward:
    curriculum:
      - name: Lesson0
        completion_criteria:
          measure: reward
          behavior: CurriculumEx
          signal_smoothing: true
          min_lesson_length: 10
          threshold: 0.7
        value: 0.3
      - name: Lesson1
        completion_criteria:
          measure: reward
          behavior: CurriculumEx
          signal_smoothing: true
          min_lesson_length: 10
          threshold: 0.9
        value: 0.0
      - name: Lesson2
        value: 0.0

  episode_reward:
    curriculum:
      - name: Lesson0
        completion_criteria:
          measure: reward
          behavior: CurriculumEx
          signal_smoothing: true
          min_lesson_length: 10
          threshold: 0.7
        value: 0.0
      - name: Lesson1
        completion_criteria:
          measure: reward
          behavior: CurriculumEx
          signal_smoothing: true
          min_lesson_length: 10
          threshold: 0.9
        value: 1.0
      - name: Lesson2
        value: 2.0

  step_reward:
    curriculum:
      - name: Lesson0
        completion_criteria:
          measure: reward
          behavior: CurriculumEx
          signal_smoothing: true
          min_lesson_length: 10
          threshold: 0.7
        value: 0.0
      - name: Lesson1
        completion_criteria:
          measure: reward
          behavior: CurriculumEx
          signal_smoothing: true
          min_lesson_length: 10
          threshold: 0.9
        value: 0.0
      - name: Lesson2
        value: -0.001

```



<br>

## カリキュラム学習の実行
```
mlagents-learn .\config\sample\CurriculumEx.yaml --run-id=CurriculumEx-1
```

<img src="images/4_9_1.JPG" width="90%" alt="" title="">

<br>

## カリキュラム学習専用のグラフ

カリキュラム学習の使用時には、「TensorBoard」でカリキュラム学習専用のグラフも提供されます。

#### Lesson Numberグラフ

環境パラメータ毎のレッスンの進捗状況を示すグラフです。

<img src="images/4_9_1_2.JPG" width="90%" alt="" title="">

<br>

## カリキュラム学習の「あり」と「なし」の比較

「カリキュラム学習」の「あり」と「なし」を比較してみます。「カリキュラム学習」なしは、最初から「レッスン2」のパラメータのみで学習しました。  
学習結果のグラフは、次のとおりです。難易度の高い「レッスン2」から始めてしまうと、まったく報酬が見つけられないことがわかります。

<img src="images/4_9_1_3.JPG" width="90%" alt="" title="">

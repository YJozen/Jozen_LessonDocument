3. Unity ML-Agents 基礎 

# 3-1 状態と観察


## Vector Observations

Stacked Vector


現在の決定に利用する観察「」「」

・現在の観察　　　　→「」
・１フレーム前の観察→「」


CoollectObservations()


    // 観測を収集するために呼び出されます
    public override void CollectObservations(VectorSensor sensor)
    {
        // エージェントとターゲットの相対位置を観測
        sensor.AddObservation(targetTransform.localPosition - transform.localPosition);
    }



のようにする


# 観察の設定

+ 

+ 




## 3-2 行動

### 行動とは




### Continuous 連続


### Discrete


### 行動を設定する際のポイント


## 3-3 報酬とエピソード完了

### 報酬


####

####



### エピソードの完了　2種類
+ MaxStep
+ EndEpisode()


## 3-4 決定


## 3-5 学習設定ファイル

### 

#### PPOとSAC

基本的にPPO

4-1でSACについて
PPO




5-15 でMA-POCA




#### トレーナーの種別



#### ハイパーパラメーター


#### 学習アルゴリズム

##### PPOとSAC共通


#### ニューラルネットワーク

勾配降下


## 3-6 mlagebts-learn



## 3-7 TEnsorBoard

学習とは別のプロンプト



仮想環境で

tensorboard --logdir=./results


# scalars


step
relative
wall



## enviroment
+ 
+ 

## losses
## policy



